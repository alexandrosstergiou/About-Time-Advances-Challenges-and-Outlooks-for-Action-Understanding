\RequirePackage{fix-cm}
\documentclass[smallextended,twocolumn,natbib]{svjour3}
\usepackage[colorlinks,citecolor=blue,linkcolor=blue]{hyperref}
%\usepackage[style=authoryear,natbib=true]{biblatex}
%\addbibresource{egbib.bib}
\setcitestyle{numbers}
\bibliographystyle{ieeetr}
\smartqed  % flush right qed marks, e.g. at end of proof
%
\makeatletter
\def\cl@chapter{\cl@chapter \@elt {theorem}}%bug in class
\def\cl@chapter{\@elt {theorem}}
% Patch case where name and year are separated by aysep

\patchcmd{\NAT@citex}
  {\@citea\NAT@hyper@{%
     \NAT@nmfmt{\NAT@nm}%
     \hyper@natlinkbreak{\NAT@aysep\NAT@spacechar}{\@citeb\@extra@b@citeb}%
     \NAT@date}}
  {\@citea\NAT@nmfmt{\NAT@nm}%
   \NAT@aysep\NAT@spacechar\NAT@hyper@{\NAT@date}}{}{}

% Patch case where name and year are separated by opening bracket
\patchcmd{\NAT@citex}
  {\@citea\NAT@hyper@{%
     \NAT@nmfmt{\NAT@nm}%
     \hyper@natlinkbreak{\NAT@spacechar\NAT@@open\if*#1*\else#1\NAT@spacechar\fi}%
       {\@citeb\@extra@b@citeb}%
     \NAT@date}}
  {\@citea\NAT@nmfmt{\NAT@nm}%
   \NAT@spacechar\NAT@@open\if*#1*\else#1\NAT@spacechar\fi\NAT@hyper@{\NAT@date}}
  {}{}
\makeatother


%\documentclass[lettersize,journal]{IEEEtran}

%% The amssymb package provides various useful mathematical symbols
\usepackage{footmisc} % enabling footnotes.
\usepackage[dvipsnames]{xcolor,colortbl}
\usepackage{soul}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{array}
\usepackage{lineno}
\usepackage{comment}
\usepackage{multirow}
\usepackage{cite}
\usepackage{threeparttable,booktabs}
%\usepackage[numbers,sort&compress]{natbib}
\usepackage{expl3,xparse}
\usepackage{etoolbox}
\renewcommand{\tablename}{Table}
%\usepackage[justification=centering]{caption} % Figures caption
\usepackage{subcaption}
\captionsetup{labelsep = period} 
\renewcommand{\figurename}{Fig.} % Fig.2 (rather than Figure 2)
\usepackage[export]{adjustbox}
%\usepackage{caption, subcaption}
\usepackage{diagbox}
\usepackage{tikz}
\usepackage{totcount}
\usepackage{overpic}
\newtotcounter{citenum}
\usepackage{footnotebackref}
\usepackage{pifont}
\usepackage{bbm}
\usepackage{tabstackengine}
\usepackage{makecell}
%\captionsetup{%
%    justification=Justified,%
%}
%\def\oldbibitem{} \let\oldbibitem=\bibitem
%\def\bibitem{\stepcounter{citnum}\oldbibitem}

% Include other packages here, before hyperref.

\usepackage{cleveref}
\definecolor{applegreen}{rgb}{0.0, 0.5, 0.0}
\definecolor{cadmiumred}{rgb}{0.89, 0.0, 0.13}
\definecolor{LightGrey}{rgb}{0.9,0.9,0.9}
\definecolor{babyblue}{HTML}{7EA6E0}
\definecolor{fadedred}{HTML}{EA6B66}
\definecolor{pastelorange}{HTML}{FFB570}
\definecolor{pastelteal}{HTML}{67AB9F}
\definecolor{pastelpurple}{HTML}{B5739D}




\newcommand\tstrut{\rule{0pt}{2.4ex}}
\newcommand\bstrut{\rule[-1.0ex]{0pt}{0pt}}

\newcommand\blfootnote[1]{%
  \begingroup
  \renewcommand\thefootnote{}\footnote{#1}%
  \addtocounter{footnote}{-1}%
  \endgroup
}

\newtotcounter{citnum} %From the package documentation
\def\oldbibitem{} \let\oldbibitem=\bibitem
\def\bibitem{\stepcounter{citnum}\oldbibitem}
%\AtEveryBibitem{\stepcounter{citnum}}


\newcommand*{\upSmallFrown}{\mathbin{\raisebox{0.9ex}{$\smallfrown$}}}

\newcommand{\pcite}[1]{\textcolor{gray}{\citep{#1}}}
\newcommand{\tcite}[1]{\textcolor{gray}{\citet{#1}}}

\setcounter{tocdepth}{2}
\usepackage{balance}
\usepackage{newpxtext}

\makeatletter
\newcommand{\ie}{\emph{i.e.}\@ifnextchar.{\!\@gobble}{}}
\newcommand{\eg}{\emph{e.g.}\@ifnextchar.{\!\@gobble}{}}
\newcommand{\etc}{etc\@ifnextchar.{}{.\@}}

\makeatother

\begin{document}

\sloppy

\title{About Time: Advances, Challenges, and Outlooks of Action Understanding}




\author{Alexandros Stergiou \and Ronald Poppe}
\institute{A. Stergiou \at Faculty of Electrical Engineering, Mathematics and Computer Science at the University of Twente, Drienerlolaan 5, 7522 NB Enschede, The Netherlands   
\and
R.Poppe \at Department of Information and Computing Sciences at Utrecht University, Princetonplein 5, 3584 CC Utrecht, The Netherlands
}
%\date{Received: date / Accepted: date}
% The correct dates will be entered by the editor


\maketitle

\begin{abstract}
We have witnessed impressive advances in video action understanding. Increased dataset sizes, variability, and computation availability have enabled leaps in performance and task diversification. Current systems can provide coarse- and fine-grained descriptions of video scenes, extract segments corresponding to queries, synthesize unobserved parts of videos, and predict context across multiple modalities. This survey comprehensively reviews advances in uni- and multi-modal action understanding across a range of tasks. We focus on prevalent challenges, overview widely adopted datasets, and survey seminal works with an emphasis on recent advances. We broadly distinguish between three temporal scopes: (1) recognition tasks of actions observed in full, (2) prediction tasks for ongoing partially observed actions, and (3) forecasting tasks for subsequent unobserved action(s). This division allows us to identify specific action modeling and video representation challenges. Finally, we outline future directions to address current shortcomings.
\end{abstract}


\keywords{Action Understanding \and Action Recognition \and Action Prediction \and Action Anticipation}

\newpage
%% main text

\begin{figure*}[t]
    \centering
    \begin{overpic}[width=\linewidth]{figs/action_understanding_task_roadmap.pdf}
    %1 -- FINAL
    \put (0.8,3.53) {\fontsize{4.3}{4}\selectfont \citet{wren1997pfinder}} % Pose estimation
    \put (0.8,6.55) {\fontsize{4.3}{4}\selectfont \citet{bobick2001recognition}} % Motion tracking

    %2 -- FINAL
    \put (25.25,3.38) {\fontsize{4.3}{4}\selectfont \citet{schuldt2004recognizing}} % Classification
    \put (36.3,3.38) {\fontsize{4.3}{4}\selectfont \citet{vinciarelli2012bridging}} % NV interact rec
    \put (47.35,3.38) {\fontsize{4.3}{4}\selectfont \citet{weinland2010makingaction}} % Interest point detect
    \put (58.4,3.38) {\fontsize{4.3}{4}\selectfont \citet{kim2009observe}} % VAD (close-set)
    \put (36.3,0.36) {\fontsize{4.3}{4}\selectfont \citet{rehg2013decoding}} % Behavior analysis
    \put (25.25,0.36) {\fontsize{4.3}{4}\selectfont \citet{jain2015whatdo}} % Object detect
    \put (47.35,0.36) {\fontsize{4.3}{4}\selectfont \citet{wang2013dense}} % Local feat. track
    \put (58.4,0.36) {\fontsize{4.3}{4}\selectfont \citet{yao2010modeling}} % Human-object interact.
    \put (69.45,0.36) {\fontsize{4.3}{4}\selectfont \citet{benfold2011stable}} % Multi-object track

    %3 -- FINAL
    \put (1.65,11.2) {\fontsize{4.3}{4}\selectfont \citet{gaidon2013temporal}} % TAL
    \put (13.2,11.2) {\fontsize{3.7}{4}\selectfont \citet{takano2015statistical}} % Motion captioning
    \put (1.65,14.2) {\fontsize{4.3}{4}\selectfont \citet{song2011multiple}} % Video ret. (inst.)
    \put (13.2,14.2) {\fontsize{4.3}{4}\selectfont \citet{choi2012unified}} % Group act. rec.
    \put (1.65,17.1) {\fontsize{4.3}{4}\selectfont \citet{guadarrama2013youtube2text}} % Video cap. (single)
    \put (13.2,17.1) {\fontsize{3.9}{4}\selectfont \citet{hoai2014max}} % Action spotting

    %4 -- FINAL
    \put (36.55,13.32) {\fontsize{4.3}{4}\selectfont \citet{zhou2013hierarchical}} % Action segmentation
    \put (36.55,10.35) {\fontsize{4.3}{4}\selectfont \citet{wang2014learning}} % 3d act rec
    \put (36.55,7.39) {\fontsize{4.3}{4}\selectfont \citet{oreifej2013hon4d}} % point cloud rec.

    %5 -- FINAL
    \put (53.25,13.32) {\fontsize{4.3}{4}\selectfont \citet{kataoka2016recognition}} % APP
    \put (53.25,10.34) {\fontsize{4.3}{4}\selectfont \citet{xu2015learning}} % VAD (open-set)
    \put (53.24,7.38) {\fontsize{4.3}{4}\selectfont \citet{joo2015panoptic}} % Panoptic rec.
    \put (64.38,13.32) {\fontsize{4.3}{4}\selectfont \citet{aytar2016soundnet}} % Audiovisual rec
    \put (64.38,10.34) {\fontsize{4.3}{4}\selectfont \citet{vondrick2016generating}} % Video generation 

    %6 -- FINAL
    \put (2.50,21.16) {\fontsize{4.3}{4}\selectfont \citet{shang2017video}} % Act. graph gen.
    \put (13.65,21.16) {\fontsize{4.3}{4}\selectfont \citet{damen2018scaling}} % Egocentric rec.
    \put (24.65,21.16) {\fontsize{4.3}{4}\selectfont \citet{baque2017deep}} % Multiview detection
    \put (2.50,24.17) {\fontsize{4.3}{4}\selectfont \citet{singh2017online}} % STAD
    \put (13.65,24.17) {\fontsize{4.3}{4}\selectfont \citet{liang2017dual}} % VFP
    \put (24.65,24.17) {\fontsize{4.3}{4}\selectfont \citet{zhou2018towards}} % Z/F.shot classic.
    
    %7 -- FINAL
    \put (51.65,24.12) {\fontsize{4.3}{4}\selectfont \citet{gammulle2019predicting}} % EAP
    \put (63.2,24.12) {\fontsize{4.0}{4}\selectfont \citet{furnari2019would}} % AA
    \put (51.65,21.11) {\fontsize{4.3}{4}\selectfont \citet{wray2021semantic}} % Video ret (semantic)
    \put (63.2,21.11) {\fontsize{3.1}{4}\selectfont \citet{arandjelovic2018objects}} % Audio source loc.
    \put (74.9,21.11) {\fontsize{4.3}{4}\selectfont \citet{gao2020listen}} % Audiovisual det.
    \put (51.65,18.18) {\fontsize{4.3}{4}\selectfont \citet{dwibedi2018temporal}} % VA
    \put (63.2,18.18) {\fontsize{4.3}{4}\selectfont \citet{doughty2018s}} % Skill determination
    \put (74.85,18.18) {\fontsize{4.3}{4}\selectfont \citet{korbar2019scsampler}} % Video reduction
    \put (85.95,18.18) {\fontsize{4.3}{4}\selectfont \citet{mun2019streamlined}} % Video Cap. (dense)

    %8 -- FINAL
    \put (1.5,31.95) {\fontsize{4.3}{4}\selectfont \citet{gong2022future}} % AA (long-term)
    \put (13.18,31.95) {\fontsize{4.3}{4}\selectfont \citet{ragusa2021meccano}} % AOD
    \put (24.88,31.95) {\fontsize{4.3}{4}\selectfont \citet{shou2021generic}} % EBD
    \put (35.98,31.95) {\fontsize{4.3}{4}\selectfont \citet{hu2022transrac}} % VRC
    \put (1.5,28.95) {\fontsize{4.3}{4}\selectfont \citet{yang2021just}} % VideoQA (mc)
    \put (13.18,28.95) {\fontsize{4.3}{4}\selectfont \citet{wang2022negative}} % TSG
    \put (24.88,28.95) {\fontsize{4.3}{4}\selectfont \citet{pan2020adversarial}} % Cross-domain rec.
    \put (35.98,28.95) {\fontsize{4.3}{4}\selectfont \citet{dessalene2021forecasting}} % Next active object

    %9 -- FINAL
    \put (75.3,31.11) {\fontsize{4.3}{4}\selectfont \citet{tewel2022zero}} % Z/F-shot vid. cap.
    \put (75.3,28.17) {\fontsize{4.3}{4}\selectfont \citet{bachmann2022multimae}} % SSL
    \put (75.3,25.23) {\fontsize{4.3}{4}\selectfont \citet{souvcek2022look}} % OSCD
    \put (87.5,31.11) {\fontsize{4.3}{4}\selectfont \citet{yang2022zero}} % Z/F-shot VideoQA
    \put (87.5,28.17) {\fontsize{4.3}{4}\selectfont \citet{ko2023open}} % VideoQA (open)
    \put (87.5,25.23) {\fontsize{4.3}{4}\selectfont \citet{liang2022visual}} % VAR

    %10 -- FINAL
    \put (12.45,35.94) {\fontsize{4.3}{4}\selectfont \citet{han2024autoadiii}} %  video storytelling
    \put (24.1,35.94) {\fontsize{4.3}{4}\selectfont \citet{wang2024omnivid}} %  video summ.
    \put (35.75,35.94) {\fontsize{4.3}{4}\selectfont \citet{pan2024synthesizing}} %  story continuation
    \put (47.4,35.94) {\fontsize{4.3}{4}\selectfont \citet{videoworldsimulators2024}} %  T2V generation
    \put (58.45,35.94) {\fontsize{4.3}{4}\selectfont \citet{renconsisti2v}} %  I2V generation
    \end{overpic}
    \vspace{1em}
    \resizebox{\linewidth}{!}{
    \begin{tabular}{l l l l l}
        \multicolumn{5}{l}{\textbf{Abbreviations used}} \\
         \textbf{NVIR}: Non-Verbal Interaction Recognition & 
         \textbf{VAD}: Video Anomaly Detection & 
         \textbf{VC}: Video Captioning &
         \textbf{VR}: Video Retrieval &
         \textbf{TAL}: Temporal Action Localization \\
         \textbf{APP}: Action Progress Prediction & 
         \textbf{EAP}: Early Action Prediction &
         \textbf{VA}: Video Alignment &
         \textbf{AA}: Action Anticipation & 
         \textbf{STAD}: SpetaoTemporal Action Detection \\ 
         \textbf{VFP}: Video Frame Prediction & 
         \textbf{Z/F}: Zero- and Few-shot & 
         \textbf{AOD}: Active Object Detection & 
         \textbf{TSG}: Temporal Sentence Grounding & 
         \textbf{EBD}: Event Boundary Detection \\ 
         \textbf{VRC}: Video Repetition Counting & 
         \textbf{OSCD}: Object State Change Detection & 
         \textbf{VAR}: Video Abductive Reasoning &
         \textbf{T2V}: Text to Video Generation &
         \textbf{I2V}: Image to Video Generation \\ 
    \end{tabular}
    }
    \caption{\textbf{Action understanding historical overview}. We present popular tasks across time periods. Landmark papers are selected by their relevance to the period's trends. Most tasks remain popular today.}
    \label{fig:roadmap}
\end{figure*}

\tableofcontents

\input{sec1}
\input{sec2}
\input{sec3}
\input{sec4}
\input{sec5}
\input{sec6}
\input{sec7n8}




{
\bibliography{egbib}
}



\end{document}
\endinput
%%
%% End of file `elsarticle-template-num.tex'.
